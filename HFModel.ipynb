{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/machingwen/CLIP/blob/main/HFModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1> <a href=\"http://arxiv.org/abs/2406.07524\">Simple and Effective Masked Diffusion Language Models</a> by Sahoo et al., 2024 </h1>\n",
        "\n",
        "This Colab provides a basic demonstration of using an HF model to generate examples from our paper. The model, featuring a context length of `1024`, was trained on the OpenWebText dataset for 1 million training steps, processing approximately `33B` tokens.\n",
        "\n",
        "**NOTE:** The HF model employed in this Colab does not utilize `Flash Attention`, and all intermediate computations are performed in `fp32` because the T4 GPU on Google Colab does not support Flash Attention.\n",
        "\n",
        "\n",
        "\n",
        "ğŸ“– paper: http://arxiv.org/abs/2406.07524\n",
        "\n",
        "ğŸ• code: https://github.com/kuleshov-group/mdlm\n",
        "\n",
        "ğŸ“‘ Blog: https://s-sahoo.com/mdlm/\n",
        "\n",
        "ğŸ¤— Huggingface: https://huggingface.co/kuleshov-group/mdlm-owt"
      ],
      "metadata": {
        "id": "Qzu4e3GZ2RTH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install Dependencies"
      ],
      "metadata": {
        "id": "38pXlLKT2Voq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Please ignore any warnings while installing the dependencies\n",
        "\n",
        "! pip install torch==2.2.2 torchvision==0.17.2 torchaudio==2.2.2 --index-url https://download.pytorch.org/whl/cu121\n",
        "! pip install causal-conv1d\n",
        "! pip install datasets==2.18.0\n",
        "! pip install einops==0.7.0\n",
        "! pip install fsspec\n",
        "! pip install git-lfs==1.6\n",
        "! pip install h5py==3.10.0\n",
        "! pip install hydra-core==1.3.2\n",
        "! pip install lightning==2.2.1\n",
        "! pip install mamba-ssm\n",
        "! pip install nvitop==1.3.2\n",
        "! pip install omegaconf==2.3.0\n",
        "! pip install packaging==23.2\n",
        "! pip install pandas\n",
        "! pip install rich==13.7.1\n",
        "! pip install seaborn==0.13.2\n",
        "! pip install scikit-learn==1.4.0\n",
        "! pip install timm==0.9.16\n",
        "! pip install transformers==4.38.2\n",
        "! pip install triton==2.2.0\n",
        "! pip install wandb==0.13.5\n",
        "! pip install flash-attn==2.5.6"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jW9PYzbTz2bR",
        "outputId": "1f318450-7ae2-478d-c055-f44ca538575d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from mamba-ssm) (2.2.2+cu121)\n",
            "Collecting ninja (from mamba-ssm)\n",
            "  Using cached ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from mamba-ssm) (0.7.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from mamba-ssm) (4.50.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from mamba-ssm) (24.2)\n",
            "Requirement already satisfied: setuptools>=61.0.0 in /usr/local/lib/python3.11/dist-packages (from mamba-ssm) (75.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->mamba-ssm) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->mamba-ssm) (4.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch->mamba-ssm) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->mamba-ssm) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->mamba-ssm) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->mamba-ssm) (2024.2.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->mamba-ssm) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->mamba-ssm) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->mamba-ssm) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.11/dist-packages (from torch->mamba-ssm) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch->mamba-ssm) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch->mamba-ssm) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch->mamba-ssm) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch->mamba-ssm) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch->mamba-ssm) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.11/dist-packages (from torch->mamba-ssm) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->mamba-ssm) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->mamba-ssm) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->mamba-ssm) (12.5.82)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers->mamba-ssm) (0.30.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers->mamba-ssm) (2.0.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers->mamba-ssm) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers->mamba-ssm) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers->mamba-ssm) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers->mamba-ssm) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers->mamba-ssm) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers->mamba-ssm) (4.67.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->mamba-ssm) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers->mamba-ssm) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers->mamba-ssm) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers->mamba-ssm) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers->mamba-ssm) (2025.1.31)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch->mamba-ssm) (1.3.0)\n",
            "Using cached ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (422 kB)\n",
            "Building wheels for collected packages: mamba-ssm\n",
            "  Building wheel for mamba-ssm (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mamba-ssm: filename=mamba_ssm-2.2.4-cp311-cp311-linux_x86_64.whl size=323672993 sha256=8a0be01153fa30727a9e69024fbe061eb92c7ba4416d2049c5fc3107ed91d852\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/5e/64/cfcb5dfe4f854944456e031c34953dc872af1ad7c206145d4a\n",
            "Successfully built mamba-ssm\n",
            "Installing collected packages: ninja, mamba-ssm\n",
            "Successfully installed mamba-ssm-2.2.4 ninja-1.11.1.4\n",
            "Collecting nvitop==1.3.2\n",
            "  Downloading nvitop-1.3.2-py3-none-any.whl.metadata (78 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m78.2/78.2 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-ml-py<12.536.0a0,>=11.450.51 (from nvitop==1.3.2)\n",
            "  Downloading nvidia_ml_py-12.535.161-py3-none-any.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: psutil>=5.6.6 in /usr/local/lib/python3.11/dist-packages (from nvitop==1.3.2) (5.9.5)\n",
            "Requirement already satisfied: cachetools>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from nvitop==1.3.2) (5.5.2)\n",
            "Requirement already satisfied: termcolor>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from nvitop==1.3.2) (3.0.1)\n",
            "Downloading nvitop-1.3.2-py3-none-any.whl (215 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m215.4/215.4 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_ml_py-12.535.161-py3-none-any.whl (37 kB)\n",
            "Installing collected packages: nvidia-ml-py, nvitop\n",
            "  Attempting uninstall: nvidia-ml-py\n",
            "    Found existing installation: nvidia-ml-py 12.570.86\n",
            "    Uninstalling nvidia-ml-py-12.570.86:\n",
            "      Successfully uninstalled nvidia-ml-py-12.570.86\n",
            "Successfully installed nvidia-ml-py-12.535.161 nvitop-1.3.2\n",
            "Requirement already satisfied: omegaconf==2.3.0 in /usr/local/lib/python3.11/dist-packages (2.3.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.11/dist-packages (from omegaconf==2.3.0) (4.9.3)\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from omegaconf==2.3.0) (6.0.2)\n",
            "Collecting packaging==23.2\n",
            "  Downloading packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: packaging\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.2\n",
            "    Uninstalling packaging-24.2:\n",
            "      Successfully uninstalled packaging-24.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.18.0 requires h5py>=3.11.0, but you have h5py 3.10.0 which is incompatible.\n",
            "google-cloud-bigquery 3.31.0 requires packaging>=24.2.0, but you have packaging 23.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed packaging-23.2\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Collecting rich==13.7.1\n",
            "  Downloading rich-13.7.1-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich==13.7.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich==13.7.1) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich==13.7.1) (0.1.2)\n",
            "Downloading rich-13.7.1-py3-none-any.whl (240 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m240.7/240.7 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rich\n",
            "  Attempting uninstall: rich\n",
            "    Found existing installation: rich 13.9.4\n",
            "    Uninstalling rich-13.9.4:\n",
            "      Successfully uninstalled rich-13.9.4\n",
            "Successfully installed rich-13.7.1\n",
            "Requirement already satisfied: seaborn==0.13.2 in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /usr/local/lib/python3.11/dist-packages (from seaborn==0.13.2) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.11/dist-packages (from seaborn==0.13.2) (2.2.2)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /usr/local/lib/python3.11/dist-packages (from seaborn==0.13.2) (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn==0.13.2) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn==0.13.2) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn==0.13.2) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn==0.13.2) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn==0.13.2) (23.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn==0.13.2) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn==0.13.2) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn==0.13.2) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn==0.13.2) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn==0.13.2) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn==0.13.2) (1.17.0)\n",
            "Collecting scikit-learn==1.4.0\n",
            "  Downloading scikit_learn-1.4.0-1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting numpy<2.0,>=1.19.5 (from scikit-learn==1.4.0)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.4.0) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.4.0) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.4.0) (3.6.0)\n",
            "Downloading scikit_learn-1.4.0-1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m74.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m71.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy, scikit-learn\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.6.1\n",
            "    Uninstalling scikit-learn-1.6.1:\n",
            "      Successfully uninstalled scikit-learn-1.6.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.18.0 requires h5py>=3.11.0, but you have h5py 3.10.0 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.4 scikit-learn-1.4.0\n",
            "Collecting timm==0.9.16\n",
            "  Downloading timm-0.9.16-py3-none-any.whl.metadata (38 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from timm==0.9.16) (2.2.2+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from timm==0.9.16) (0.17.2+cu121)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from timm==0.9.16) (6.0.2)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from timm==0.9.16) (0.30.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from timm==0.9.16) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm==0.9.16) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm==0.9.16) (2024.2.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm==0.9.16) (23.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm==0.9.16) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm==0.9.16) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm==0.9.16) (4.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch->timm==0.9.16) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->timm==0.9.16) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->timm==0.9.16) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->timm==0.9.16) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->timm==0.9.16) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->timm==0.9.16) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.11/dist-packages (from torch->timm==0.9.16) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch->timm==0.9.16) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch->timm==0.9.16) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch->timm==0.9.16) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch->timm==0.9.16) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch->timm==0.9.16) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.11/dist-packages (from torch->timm==0.9.16) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->timm==0.9.16) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->timm==0.9.16) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->timm==0.9.16) (12.5.82)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision->timm==0.9.16) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->timm==0.9.16) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->timm==0.9.16) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm==0.9.16) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm==0.9.16) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm==0.9.16) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm==0.9.16) (2025.1.31)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch->timm==0.9.16) (1.3.0)\n",
            "Downloading timm-0.9.16-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m75.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: timm\n",
            "  Attempting uninstall: timm\n",
            "    Found existing installation: timm 1.0.15\n",
            "    Uninstalling timm-1.0.15:\n",
            "      Successfully uninstalled timm-1.0.15\n",
            "Successfully installed timm-0.9.16\n",
            "Collecting transformers==4.38.2\n",
            "  Downloading transformers-4.38.2-py3-none-any.whl.metadata (130 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m130.7/130.7 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.38.2) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.11/dist-packages (from transformers==4.38.2) (0.30.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.38.2) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.38.2) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.38.2) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.38.2) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.38.2) (2.32.3)\n",
            "Collecting tokenizers<0.19,>=0.14 (from transformers==4.38.2)\n",
            "  Downloading tokenizers-0.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.38.2) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.38.2) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.38.2) (2024.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.38.2) (4.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.38.2) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.38.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.38.2) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.38.2) (2025.1.31)\n",
            "Downloading transformers-4.38.2-py3-none-any.whl (8.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m108.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m96.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tokenizers, transformers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.21.1\n",
            "    Uninstalling tokenizers-0.21.1:\n",
            "      Successfully uninstalled tokenizers-0.21.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.50.3\n",
            "    Uninstalling transformers-4.50.3:\n",
            "      Successfully uninstalled transformers-4.50.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "sentence-transformers 3.4.1 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.38.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed tokenizers-0.15.2 transformers-4.38.2\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.11/dist-packages (2.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from triton==2.2.0) (3.18.0)\n",
            "Collecting wandb==0.13.5\n",
            "  Downloading wandb-0.13.5-py2.py3-none-any.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.11/dist-packages (from wandb==0.13.5) (8.1.8)\n",
            "Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb==0.13.5) (3.1.44)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb==0.13.5) (2.32.3)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.11/dist-packages (from wandb==0.13.5) (2.3)\n",
            "Collecting shortuuid>=0.5.0 (from wandb==0.13.5)\n",
            "  Downloading shortuuid-1.0.13-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb==0.13.5) (5.9.5)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb==0.13.5) (2.25.1)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.11/dist-packages (from wandb==0.13.5) (1.17.0)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb==0.13.5) (0.4.0)\n",
            "Collecting protobuf!=4.0.*,!=4.21.0,<5,>=3.12.0 (from wandb==0.13.5)\n",
            "  Downloading protobuf-4.25.6-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from wandb==0.13.5) (6.0.2)\n",
            "Collecting pathtools (from wandb==0.13.5)\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb==0.13.5) (1.3.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb==0.13.5) (75.2.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from GitPython>=1.0.0->wandb==0.13.5) (4.0.12)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb==0.13.5) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb==0.13.5) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb==0.13.5) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb==0.13.5) (2025.1.31)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb==0.13.5) (5.0.2)\n",
            "Downloading wandb-0.13.5-py2.py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m70.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-4.25.6-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading shortuuid-1.0.13-py3-none-any.whl (10 kB)\n",
            "Building wheels for collected packages: pathtools\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8792 sha256=267f038ae699307e64000b7a9140bb3d430695cbf30112ff3aea266599ebb109\n",
            "  Stored in directory: /root/.cache/pip/wheels/ea/b7/8b/84e94095ea418b9442f5abeba4ca7b0ad52d3fe7b69d6238a6\n",
            "Successfully built pathtools\n",
            "Installing collected packages: pathtools, shortuuid, protobuf, wandb\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.4\n",
            "    Uninstalling protobuf-5.29.4:\n",
            "      Successfully uninstalled protobuf-5.29.4\n",
            "  Attempting uninstall: wandb\n",
            "    Found existing installation: wandb 0.19.9\n",
            "    Uninstalling wandb-0.19.9:\n",
            "      Successfully uninstalled wandb-0.19.9\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.18.0 requires h5py>=3.11.0, but you have h5py 3.10.0 which is incompatible.\n",
            "ydf 0.11.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 4.25.6 which is incompatible.\n",
            "grpcio-status 1.71.0 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.6 which is incompatible.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.2.0 which is incompatible.\n",
            "google-cloud-bigquery 3.31.0 requires packaging>=24.2.0, but you have packaging 23.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pathtools-0.1.2 protobuf-4.25.6 shortuuid-1.0.13 wandb-0.13.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Git clone"
      ],
      "metadata": {
        "id": "Z6RlAoYS8ctO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/kuleshov-group/mdlm.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQqN0nvC2J_R",
        "outputId": "99eef37b-79de-482f-8f6c-8130f645d7b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'mdlm'...\n",
            "remote: Enumerating objects: 122, done.\u001b[K\n",
            "remote: Counting objects: 100% (122/122), done.\u001b[K\n",
            "remote: Compressing objects: 100% (93/93), done.\u001b[K\n",
            "remote: Total 122 (delta 38), reused 107 (delta 25), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (122/122), 89.98 KiB | 4.74 MiB/s, done.\n",
            "Resolving deltas: 100% (38/38), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "e0w_J0_l0bCq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('mdlm')\n",
        "\n",
        "import fsspec\n",
        "import hydra\n",
        "import lightning as L\n",
        "import omegaconf\n",
        "import rich.syntax\n",
        "import rich.tree\n",
        "import torch\n",
        "\n",
        "import dataloader\n",
        "import diffusion\n",
        "import main\n",
        "import utils"
      ],
      "metadata": {
        "id": "xQtG7EAl0Wcr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sample generation"
      ],
      "metadata": {
        "id": "m1wUkbWt4Nty"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "overrides=['mode=sample_eval',\n",
        "           'eval.checkpoint_path=kuleshov-group/mdlm-no_flashattn-fp32-owt',\n",
        "           'data=openwebtext-split',\n",
        "           'model.length=1024',\n",
        "           'sampling.predictor=ddpm_cache',\n",
        "           'sampling.steps=1000',\n",
        "           'loader.eval_batch_size=1',\n",
        "           'sampling.num_sample_batches=1',\n",
        "           'backbone=hf_dit']\n",
        "\n",
        "with hydra.initialize(version_base=None,\n",
        "                      config_path='configs'):\n",
        "  config = hydra.compose(config_name='config', overrides=overrides)\n",
        "  sar_config = hydra.compose(config_name='config', overrides=overrides)"
      ],
      "metadata": {
        "id": "EAsXS-O63NIR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "L.seed_everything(config.seed)\n",
        "\n",
        "logger = utils.get_logger(__name__)\n",
        "tokenizer = dataloader.get_tokenizer(config)\n",
        "\n",
        "samples = main.generate_samples(config, logger, tokenizer)\n",
        "for sample in samples:\n",
        "  print(sample)"
      ],
      "metadata": {
        "id": "FjyhWkZS-R3F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4da4662-038b-45fd-faa5-9f0274a05744"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<|endoftext|> do something else and then just work on yourself. You give them a lot of time. So itâ€™s quicker.\n",
            "\n",
            "KO: Youâ€™ve been placed there and thereâ€™s been the work there already: working on your game; working on effort; working on progress. How does that feel to be around?\n",
            "\n",
            "BODYBOARD GETHER: It does give everybody a job to keep spending their time in the game, working on everything. And doing stuff better is just getting around to contributions already made.\n",
            "\n",
            "RANDON WILLIGAN: There are a lot of stars in the game who have a little bit more experience in South Australia. How was it like to have that?\n",
            "\n",
            "JOSEL LA PASCO: It was a huge difference. So much for my age group, you were never going to play here in Adelaide, which I did because I wasnâ€™t offer a contract, pretty much everything.\n",
            "\n",
            "In my third year I didnâ€™t earn a home contract for that. I had a lot of time overseas, varying in the skills and competitions, in the smaller league, but I had so much further time at home. That, yeah. That was tough. But then I got to Adelaide and it was really good for me.\n",
            "\n",
            "I think itâ€™s like 2013. But itâ€™s been a long time after, so if there was anything generally at the same pretty young age as I entered Origin kicked football team, it was 2008.\n",
            "\n",
            "That difference was made so quick. I know Iâ€™m still too young. You have so much experience that you wouldnâ€™t have felt comfortable at just a couple of months. Why didnâ€™t Iâ€™m in Origin ball for such an age? And then because Origin games take so long, you know why I would be making that group of mistakes. So much changing though, so much coming out.\n",
            "\n",
            "Iâ€™m looking forward to stepping into the two next. Iâ€™m just not as good at the three impas, So many more and getting caught up with them â€“ getting kicked out of situations as well as dropping three scores.\n",
            "\n",
            "But you also have the same response for the first time, so I realise that Iâ€™m gonna need more to do. And that probably kind of helped me in Adelaide.\n",
            "\n",
            "I did so much better work with one foot on the front but I could do better with my other foot on the other side.\n",
            "\n",
            "KO: Josao LADA, thatâ€™s what the hamstring was.\n",
            "\n",
            "JOSEL MILL: I knew I needed something better. I would run the last seven, eight metres, but that part I couldnâ€™t have been as bad in as that.\n",
            "\n",
            "LILA FARA: I actually pulled the weight very good.\n",
            "\n",
            "JOSDO LADA: Incredible.\n",
            "\n",
            "KO: Kiko Thompson took around 200 metres to start pushing it.\n",
            "\n",
            "Really?\n",
            "\n",
            "KO: Yeah, full 300 metres which was 4.5 metres, 5.5 metres. Six good lifts.\n",
            "\n",
            "KO: What was your best training work?\n",
            "\n",
            "JOSEL PASCO: That one I wouldnâ€™t want to answer. It was my worst. Look, in front of me, Iâ€™m too big a head like that and I can play hands like that here, a really good hand â€“ but also been hard, I would say, with my wrists, with consequent hip tension.\n",
            "\n",
            "JONIS DAVO: Wow. It was a good first start. Also, not the kind of guy I ever played a lot for the New South Wales side. Iâ€™m round straight away he was competing, to be so hot in that area.\n",
            "\n",
            "MITTIAN: To be so hot at Aâ€™s, that was extremely good.\n",
            "\n",
            "KO: Iâ€™ve, I think Chris Taylor said something about the wear in the boots.\n",
            "\n",
            "LUIS EBIBSTER: Iâ€™ve had a bigger day before.\n",
            "\n",
            "ORMIA: Better sick than nothing, mate.\n",
            "\n",
            "KO: We both went with those boots.\n",
            "\n",
            "NAHBSON: I love the regular boot.\n",
            "\n",
            "KO: I have been really racing lot with my boot.\n",
            "\n",
            "ORMIA: It takes a bit of time. And some force in the body maybe a little bit.\n",
            "\n",
            "Everyone has had some good thoughts on boots though. Maybe you have older and wiser players, believe me, use the boot, and it really enables them to continue.\n",
            "\n",
            "IRERO PANASIO: Iâ€™ve had players, every NRL player when they used the boots, say, â€œIf you keep using the shoes thereâ€™ll be longevity and they can go on thatâ€. Thereâ€™s an element of respect for those, but no.<|endoftext|>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Semi Autoregressive sample generation"
      ],
      "metadata": {
        "id": "9WnEH41C4Rew"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sar_config['sampling']['semi_ar'] = True\n",
        "sar_config['sampling']['stride_length'] = 512\n",
        "sar_config['sampling']['num_strides'] = 2\n",
        "\n",
        "# Generates conext_length + num_strides * stride_length number of tokens.\n",
        "# In this case we generate 1024 + 2 * 512 = 2048 tokens.\n",
        "\n",
        "samples = main.generate_samples(sar_config, logger, tokenizer)\n",
        "for sample in samples:\n",
        "  print(sample)"
      ],
      "metadata": {
        "id": "sKgntI436tuL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd0ea94d-d735-4cbc-e173-2d3fefb294cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:__main__:Generating samples.\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text samples: ['<|endoftext|> fundamental principles of equality and fair treatment, but in order to get more important like fairness, what is the need to eliminate? If the accuser and the defendant have never had an equal conviction I mean how did they all know about both playing a role in this situation?\\n\\nL: Iâ€™m pretty sure someone was devastated with the Free Circuitâ€™s decision. In the matter as it stands, I was able to take a amicus brief on the court that was in favor of the defendant. That is strong enough to be the dissenting opinion on this particular issue. So Iâ€™ve been asking you for a long time. I had more than 10 years to weigh in the Free Circuitâ€™s decision. How do you weigh it in todayâ€™s second?\\n\\nCL: Now the courtâ€™s message for me is propaganda. Obviously, liberals should not embrace what conservatives said. I will act in a way based on conservative statements, and any leftist will. If the court gets the other way with me then they take it away from the liberal. In other words, the liberal who can sway the people in ways that are harmful to them. On the other hand, by punishing me, I end up with this message which clearly tells voters that the environment for me and for the peopleâ€™s representative on both sides is based on my time. Ask for insight into the votersâ€™ vote that not just on their notions and views. Voters being held accountable. I mean, I really am suspicious of judges hearing nothing that is closer to the expressed from elected officials. Chapelstein says that justice is enough basically when she says that we have banks of people. But Iâ€™m not so sure. That\\'s an important test that will pass because the votes that end up impacting the people who are held accountable and that\\'s whatâ€™s been talking about.\\n\\nâ€œFor about who you are, you need to consider the possibility of rigged elections. For instance in Wisconsin, where we find that the second most Republican state in the world is 50% Democratic, thatâ€™s just so hard for you to go any further. In most states this happens for, say, people of color. For people in college, like for instance, the system can work fine if theyâ€™re Republicans. But what you are essentially looking for is the ability, like, to figure out how to get messed with. It may mean, as Shelley said, â€œThereâ€™s somewhere else thatâ€™s going to be ready to get hit. But you need to get there first.â€...\\n\\nFR: In your brief this morning your view that EPA leadership meant that, obviously, my view is by way of saying, that we are a rigged regulatory environment and the EPA has the governmental authority to rule just the way that anyone can. Coal in my opinion is supposed to destroy the environment and destroy lives. Nobody hates their rules. In one of these first comments of the Obama administration, he said that mining is a sacred, a sacred place because regulations are one of the central decision-making means of doing business. End of story. Conservatives in Congress attacked the EPA and the NRSC faction attacked that group of Congress talking also about the mining sector.\\n\\nHow much a challenge was there about yourself before you run in your appeal: â€œA far more consistent challenge to the law is against the powerless. â€œBecause I believe that about a number of my advisers that people ought to know are into something and they cannot be pushed around blindly by people or notables that can only be their advisors. And those tactics bring wrath by the powerful because some of those people will end up running through the resistance or outside of this real-party that has taken over our system. And basically it creates a party to the party with authority. It just needs to stop.â€\\n\\nFR: One month after you wrote a brief opposing the EPA, your attorney predicted that the Supreme Court would consider that decision â€œland-ending.â€ What he thinks we should be skeptical of the Supreme Courtâ€™s selection as to whether it lies in interpreting the Constitution is clear.\\n\\nCL: I am officially not a constitutionalist...this is a still-evolving case, because the Supreme Court has never ruled in this case and wonâ€™t rule in other cases of these issues (who cares? Whew). But \"In addition, I have become constitutional lawyers since the time where you have gay judges who canâ€™t stand to make their own decisions during their term, or while their term, or just outside them for a one term. Maybe the 52 Supreme Court justices have the confidence to strike down rules they really abhor....And maybe theyâ€™re going to go along with what weâ€™re doing there.â€ Which is a good question.\\n\\nFR: Does he think the justices might be interpreting the law or constitutionally or politics to a particular political point? Does he trust<|endoftext|>bensdel Blocked Unblock Follow Following Oct 10, 2016\\n\\nHillary Clinton, who is both Clinton and Hillary Clintonâ€™s Senator for 2016, should be because of her correct and historical qualifications. More importantly because of historical qualificationsâ€™ duties to protect, in ways that they donâ€™t, to make sure that women have a level playing field with men. After she retired as of June through her credible comments on Child/Her obligations, I have been troubled with her comments on Womenâ€™s World. It and a father are among the open conect with standards of history.\\n\\nShe should once again have a level playing field of this the way she is.\\n\\nIn regards to Hillary Clintonâ€™s point to Clintonâ€™s personal history, however, it is perfectly idiotic: her opponents ever- to-whose and every time she sets her mind, it gets better. It makes sense that she is adjusting to the dispositions of the last ten years or so and think she reflects those perfectly consistent views and think they ought to be still front and center if she doesnâ€™t adjust to the way she seeks to conduct the future that their enduring lives. And it causes me that she needs an excellent better method to get answers to any and all questions. But, but thatâ€™s what keeps us talking.\\n\\nIt helps to point out that Hillary Clintonâ€™s voting record is not Trumpâ€™s fault. It is hers. The third time she tells her team that she is better and they should always be for her, they turn against him. If I was correct, itâ€™s not just that they should always be against Trump to make their odds for Trump upside-down. It was my argument how the Poor Draw and Trumpâ€™s good turn left her vulnerable more than she had it, and that the resulting minor coalition changes tilted the electorateâ€™s Electoral College to his favor.\\n\\nNow back to my read-by-tryâ€™s demonstrative account of the contrasts, after showing Hillary Trumpâ€™s results and Hillary Clintonâ€™ the brackets. On your paper, the fact that Clintonâ€™ got sixty-to-one is a difference between a close margin that Clinton â€™ hadnâ€™t been able to compare among. But on the margin they arenâ€™t even sixty-to-one, and reason for why that is why Clinton ends with an average bigger than Obamaâ€™s rests on these biases that most people fail to understand.\\n\\nSecond, Trump doesnâ€™t always have his team to tell him it right, so it appears his average are closer to Obamaâ€™s than Machinesâ€™ Machine says it is, and that he has done it all a disservice. Take the election of Hawaii, where any opposition vote cast, counted dead because of the disenfranchised cast of Blacks, ignored because it was done to work in favor of the same color, and how short the series was on, won on Romney Romney margin? is compounded. This political bias runs so important that we have St. Oâ€™s presidential correspondents ignoring Professor McLaughlin and all sides ignoring their political games.\\n\\nIt is something not a pleasure to read.\\n\\nFifth, two years must have been two years to the White House. Wade 72, died so that people couldnâ€™t say a thing. Each or two is a, the degree of defeat. Canâ€™t be substantiated. The campaign has the arguments and the people he has hired to buy up his, buy the first as well so he can show that he seems to have a harder time than he is right now.\\n\\nAnother thing is that we actually willâ€™t get to the middle of the lies yet. That means calling them in genera for their lies people not related (at the end of) is. Hillary says that with that the lies are on the exact opposite side of an Ohio states an Obama win. There would have been no discrepancy, which is why it is more likely to make an argument not if they are determined.\\n\\nIn terms of the accuracy for the FBIâ€™s emails, it was May 11, 2010, and is that week that the Hillary Clinton documents became public. May 11, 2009, and that is a month before Clinton was able to correct my response, which also if that date was not moved to May 31, 2012, corrected my mistake. The weeks before Govâ€™s Jan. 1 was the first time she has had the Clintons to her attention. Unlike the Time Bureauâ€™s list, they are of where she is not, the same place she was on May 17, 2008, so she must pay attention to the Boundless Wall in her yard.<|endoftext|>If she were a huge, clear television celebrity and her address, it would her embarrassment make her house pretty black and her faces more visible. But, when you are with many people whom you know, when you are with another person you know']\n",
            "<|endoftext|> fundamental principles of equality and fair treatment, but in order to get more important like fairness, what is the need to eliminate? If the accuser and the defendant have never had an equal conviction I mean how did they all know about both playing a role in this situation?\n",
            "\n",
            "L: Iâ€™m pretty sure someone was devastated with the Free Circuitâ€™s decision. In the matter as it stands, I was able to take a amicus brief on the court that was in favor of the defendant. That is strong enough to be the dissenting opinion on this particular issue. So Iâ€™ve been asking you for a long time. I had more than 10 years to weigh in the Free Circuitâ€™s decision. How do you weigh it in todayâ€™s second?\n",
            "\n",
            "CL: Now the courtâ€™s message for me is propaganda. Obviously, liberals should not embrace what conservatives said. I will act in a way based on conservative statements, and any leftist will. If the court gets the other way with me then they take it away from the liberal. In other words, the liberal who can sway the people in ways that are harmful to them. On the other hand, by punishing me, I end up with this message which clearly tells voters that the environment for me and for the peopleâ€™s representative on both sides is based on my time. Ask for insight into the votersâ€™ vote that not just on their notions and views. Voters being held accountable. I mean, I really am suspicious of judges hearing nothing that is closer to the expressed from elected officials. Chapelstein says that justice is enough basically when she says that we have banks of people. But Iâ€™m not so sure. That's an important test that will pass because the votes that end up impacting the people who are held accountable and that's whatâ€™s been talking about.\n",
            "\n",
            "â€œFor about who you are, you need to consider the possibility of rigged elections. For instance in Wisconsin, where we find that the second most Republican state in the world is 50% Democratic, thatâ€™s just so hard for you to go any further. In most states this happens for, say, people of color. For people in college, like for instance, the system can work fine if theyâ€™re Republicans. But what you are essentially looking for is the ability, like, to figure out how to get messed with. It may mean, as Shelley said, â€œThereâ€™s somewhere else thatâ€™s going to be ready to get hit. But you need to get there first.â€...\n",
            "\n",
            "FR: In your brief this morning your view that EPA leadership meant that, obviously, my view is by way of saying, that we are a rigged regulatory environment and the EPA has the governmental authority to rule just the way that anyone can. Coal in my opinion is supposed to destroy the environment and destroy lives. Nobody hates their rules. In one of these first comments of the Obama administration, he said that mining is a sacred, a sacred place because regulations are one of the central decision-making means of doing business. End of story. Conservatives in Congress attacked the EPA and the NRSC faction attacked that group of Congress talking also about the mining sector.\n",
            "\n",
            "How much a challenge was there about yourself before you run in your appeal: â€œA far more consistent challenge to the law is against the powerless. â€œBecause I believe that about a number of my advisers that people ought to know are into something and they cannot be pushed around blindly by people or notables that can only be their advisors. And those tactics bring wrath by the powerful because some of those people will end up running through the resistance or outside of this real-party that has taken over our system. And basically it creates a party to the party with authority. It just needs to stop.â€\n",
            "\n",
            "FR: One month after you wrote a brief opposing the EPA, your attorney predicted that the Supreme Court would consider that decision â€œland-ending.â€ What he thinks we should be skeptical of the Supreme Courtâ€™s selection as to whether it lies in interpreting the Constitution is clear.\n",
            "\n",
            "CL: I am officially not a constitutionalist...this is a still-evolving case, because the Supreme Court has never ruled in this case and wonâ€™t rule in other cases of these issues (who cares? Whew). But \"In addition, I have become constitutional lawyers since the time where you have gay judges who canâ€™t stand to make their own decisions during their term, or while their term, or just outside them for a one term. Maybe the 52 Supreme Court justices have the confidence to strike down rules they really abhor....And maybe theyâ€™re going to go along with what weâ€™re doing there.â€ Which is a good question.\n",
            "\n",
            "FR: Does he think the justices might be interpreting the law or constitutionally or politics to a particular political point? Does he trust<|endoftext|>bensdel Blocked Unblock Follow Following Oct 10, 2016\n",
            "\n",
            "Hillary Clinton, who is both Clinton and Hillary Clintonâ€™s Senator for 2016, should be because of her correct and historical qualifications. More importantly because of historical qualificationsâ€™ duties to protect, in ways that they donâ€™t, to make sure that women have a level playing field with men. After she retired as of June through her credible comments on Child/Her obligations, I have been troubled with her comments on Womenâ€™s World. It and a father are among the open conect with standards of history.\n",
            "\n",
            "She should once again have a level playing field of this the way she is.\n",
            "\n",
            "In regards to Hillary Clintonâ€™s point to Clintonâ€™s personal history, however, it is perfectly idiotic: her opponents ever- to-whose and every time she sets her mind, it gets better. It makes sense that she is adjusting to the dispositions of the last ten years or so and think she reflects those perfectly consistent views and think they ought to be still front and center if she doesnâ€™t adjust to the way she seeks to conduct the future that their enduring lives. And it causes me that she needs an excellent better method to get answers to any and all questions. But, but thatâ€™s what keeps us talking.\n",
            "\n",
            "It helps to point out that Hillary Clintonâ€™s voting record is not Trumpâ€™s fault. It is hers. The third time she tells her team that she is better and they should always be for her, they turn against him. If I was correct, itâ€™s not just that they should always be against Trump to make their odds for Trump upside-down. It was my argument how the Poor Draw and Trumpâ€™s good turn left her vulnerable more than she had it, and that the resulting minor coalition changes tilted the electorateâ€™s Electoral College to his favor.\n",
            "\n",
            "Now back to my read-by-tryâ€™s demonstrative account of the contrasts, after showing Hillary Trumpâ€™s results and Hillary Clintonâ€™ the brackets. On your paper, the fact that Clintonâ€™ got sixty-to-one is a difference between a close margin that Clinton â€™ hadnâ€™t been able to compare among. But on the margin they arenâ€™t even sixty-to-one, and reason for why that is why Clinton ends with an average bigger than Obamaâ€™s rests on these biases that most people fail to understand.\n",
            "\n",
            "Second, Trump doesnâ€™t always have his team to tell him it right, so it appears his average are closer to Obamaâ€™s than Machinesâ€™ Machine says it is, and that he has done it all a disservice. Take the election of Hawaii, where any opposition vote cast, counted dead because of the disenfranchised cast of Blacks, ignored because it was done to work in favor of the same color, and how short the series was on, won on Romney Romney margin? is compounded. This political bias runs so important that we have St. Oâ€™s presidential correspondents ignoring Professor McLaughlin and all sides ignoring their political games.\n",
            "\n",
            "It is something not a pleasure to read.\n",
            "\n",
            "Fifth, two years must have been two years to the White House. Wade 72, died so that people couldnâ€™t say a thing. Each or two is a, the degree of defeat. Canâ€™t be substantiated. The campaign has the arguments and the people he has hired to buy up his, buy the first as well so he can show that he seems to have a harder time than he is right now.\n",
            "\n",
            "Another thing is that we actually willâ€™t get to the middle of the lies yet. That means calling them in genera for their lies people not related (at the end of) is. Hillary says that with that the lies are on the exact opposite side of an Ohio states an Obama win. There would have been no discrepancy, which is why it is more likely to make an argument not if they are determined.\n",
            "\n",
            "In terms of the accuracy for the FBIâ€™s emails, it was May 11, 2010, and is that week that the Hillary Clinton documents became public. May 11, 2009, and that is a month before Clinton was able to correct my response, which also if that date was not moved to May 31, 2012, corrected my mistake. The weeks before Govâ€™s Jan. 1 was the first time she has had the Clintons to her attention. Unlike the Time Bureauâ€™s list, they are of where she is not, the same place she was on May 17, 2008, so she must pay attention to the Boundless Wall in her yard.<|endoftext|>If she were a huge, clear television celebrity and her address, it would her embarrassment make her house pretty black and her faces more visible. But, when you are with many people whom you know, when you are with another person you know\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HtJp8bLP_sPi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}